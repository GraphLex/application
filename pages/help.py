import streamlit as st

st.set_page_config(page_title="Help & Methodology", page_icon="ℹ️")

st.markdown("# User Guide & Methodology")

st.markdown("""
## 1. Overview
**[WE NEED A NAME]** is a research tool designed to map distributional relationships in Biblical texts. Unlike a standard lexicon which defines words in isolation, this application visualizes the *semantic neighborhoods* of Hebrew and Greek lemmas.

By modeling how words behave in the text—specifically, which words they appear alongside (Syntagmatic) and which words share similar contexts (Paradigmatic)—this tool allows researchers to explore the latent semantic structure of the Biblical corpus.

## 2. Methodology: How Similarity is Calculated
The network generation relies on two distinct algorithms, selectable via the **Relation Type** setting.

### A. Paradigmatic Relationships (Word2Vec)
* **What it represents:** Semantic similarity. Words are connected if they are used in similar contexts, even if they never appear together in the same verse (e.g., "King" and "Queen").
* **The Algorithm:** We utilize **Word2Vec**, a neural network-based technique that learns continuous vector representations of words.
* **The Process:**
    1.  The text is processed into lemmas using the **BHSA** (Hebrew) and **Nestle 1904** (Greek) datasets.
    2.  The model trains on your selected books to create a high-dimensional vector space.
    3.  Similarity is measured using **Cosine Similarity** between word vectors. A higher score indicates a closer semantic relationship.

### B. Syntagmatic Relationships (Co-occurrence)
* **What it represents:** Contextual association. Words are connected if they frequently appear near each other in the text (e.g., "Sheep" and "Shepherd").
* **The Algorithm:** A sliding window co-occurrence matrix.
* **The Process:**
    * The algorithm scans the text using a window size of **3 words**.
    * It counts how often a target word appears within that window of other words.
    * The resulting network displays the strongest "neighbors" based on raw proximity and frequency.

## 3. Interface Guide

### Sidebar Controls

#### **Bible Book Selection**
The model requires a corpus to learn from. You can train the model on the entire Bible, or restrict it to specific books to see how word usage changes across different authors or genres (e.g., comparing *John* vs. *Synoptics*).
* *Note: You must click **"Load Selected Books"** after making your selection to retrain the underlying model.*

#### **Relation Type**
* **Paradigmatic:** Select this to find synonyms, antonyms, or functional equivalents.
* **Syntagmatic:** Select this to find collocations and narrative partners.

#### **Word Input**
Enter the Strong's Number for your target word.
* **H Button:** Sets the prefix for Hebrew (Old Testament).
* **G Button:** Sets the prefix for Greek (New Testament).
* *Example:* To search for *Elohim*, click **H** and type **430**.

#### **Network Settings**
These controls determine the size and complexity of the visualization:
* **Number of Similar Words per Level:** The "branching factor." If set to 5, the graph will find the top 5 most similar words for your target node.
* **Search Depth:** The "degrees of separation."
    * *Depth 1:* Shows only your target word and its direct neighbors.
    * *Depth 2:* Shows the neighbors of the neighbors, revealing second-order connections.
    * *Warning:* High depth values exponentially increase the graph size and calculation time.

### Interactive Graph
The main view displays a force-directed graph generated by PyVis.
* **Zoom/Pan:** Scroll to zoom, click and drag to move the canvas.
* **Nodes:** Hover over a node to see the specific lemma.
* **Edges:** The connecting lines represent the strength of the relationship. Hover over an edge to see the specific weight (similarity score).
""")

st.info("Data Sources: Hebrew text derived from the BHSA (ETCBC); Greek text derived from the Nestle 1904 (CBLC).")